{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9fe722",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Databricks notebook source\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer, VectorAssembler, StandardScaler\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.sql.functions import col, expr\n",
    "\n",
    "# COMMAND ----------\n",
    "# Load silver data\n",
    "df = spark.sql(\"SELECT * FROM fraud_miner.silver.fraud_geo_view\")\n",
    "\n",
    "# Feature engineering: geo match\n",
    "df = df.withColumn(\"geo_matches_merchant\", (col(\"geo_country\") == col(\"Merchant_Country\")).cast(\"int\"))\n",
    "\n",
    "# Define features\n",
    "target = \"Transaction_Fraud\"\n",
    "categorical_cols = [\"Card_Provider\", \"Merchant_Category\", \"Merchant_Country\", \"geo_country\"]\n",
    "numeric_cols = [\"Transaction_Amount\", \"geo_matches_merchant\"]\n",
    "\n",
    "# StringIndexers for categoricals\n",
    "indexers = [StringIndexer(inputCol=c, outputCol=f\"{c}_idx\", handleInvalid='keep') for c in categorical_cols]\n",
    "encoders = [OneHotEncoder(inputCol=f\"{c}_idx\", outputCol=f\"{c}_vec\") for c in categorical_cols]\n",
    "\n",
    "# Vector Assembler and Scaler\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=[f\"{c}_vec\" for c in categorical_cols] + numeric_cols,\n",
    "    outputCol=\"features_raw\"\n",
    ")\n",
    "scaler = StandardScaler(inputCol=\"features_raw\", outputCol=\"features\")\n",
    "\n",
    "# Logistic Regression\n",
    "lr = LogisticRegression(labelCol=target, featuresCol=\"features\")\n",
    "\n",
    "# ML Pipeline\n",
    "pipeline = Pipeline(stages=indexers + encoders + [assembler, scaler, lr])\n",
    "\n",
    "# Cross-Validation Setup\n",
    "param_grid = ParamGridBuilder().build()\n",
    "evaluator = BinaryClassificationEvaluator(labelCol=target, metricName=\"areaUnderROC\")\n",
    "\n",
    "cv = CrossValidator(\n",
    "    estimator=pipeline,\n",
    "    estimatorParamMaps=param_grid,\n",
    "    evaluator=evaluator,\n",
    "    numFolds=10\n",
    ")\n",
    "\n",
    "# Fit model\n",
    "cv_model = cv.fit(df)\n",
    "\n",
    "# COMMAND ----------\n",
    "# Evaluate\n",
    "predictions = cv_model.transform(df)\n",
    "auc = evaluator.evaluate(predictions)\n",
    "print(f\"âœ… Final AUC: {auc:.4f}\")\n",
    "\n",
    "# COMMAND ----------\n",
    "# Save predictions (optional)\n",
    "predictions.select(\"Transaction_Fraud\", \"prediction\", \"probability\").write.mode(\"overwrite\").saveAsTable(\"fraud_miner.gold.model_predictions\")\n",
    "\n",
    "# Save AUC to evaluation table\n",
    "from pyspark.sql import Row\n",
    "result_row = Row(run_date=str(expr(\"current_timestamp()\")), auc=float(auc))\n",
    "spark.createDataFrame([result_row]).write.mode(\"append\").saveAsTable(\"fraud_miner.gold.model_evaluation\")\n",
    "\n",
    "# Save model (optional)\n",
    "# cv_model.bestModel.write().overwrite().save(\"/mnt/models/fraud_logistic_spark\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
